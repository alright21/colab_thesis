{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAN Bus IDS",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMX0CEtzEAk6rGtQTBj+XJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alright21/colab_thesis/blob/main/CAN_Bus_IDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMi_FQ2Dwe9v"
      },
      "source": [
        "# CAN Bus IDS implementation and benchmarking\n",
        "\n",
        "This project aims at implementing and comparing some of the most intersting and promising CAN bus IDS found in literature. A lot of projects and ideas has been published during last year in this area, but there is no study that wants to compare the different solutions using common data to see what perform best, what are their strengths and weaknesses.\n",
        "\n",
        "## Language, modules and tools\n",
        "\n",
        "The language of choice is python3.9 because it is a flexible language that can be quite simple to write, but at the same time it is very powerful and suitable for large data manipulation. Moreover, some of the CAN bus used machine learning structures and python has been recognized as one of the most used language for this area of study thanks to its various number of mudules.\n",
        "\n",
        "Speaking of modules, the packet generation and manipulation happened with a module called `python-can`, a complete library for reading, writing and analyzing CAN messages. It also allows to directly communicate with a real or virtual CAN bus in an easy way, but since logs were already taken. Getting the log directly from a car and checking the validity of the IDS in real time was the first idea, but there was a need for expensive hardware and extensive study on a chosen vehicle to tweak the bus reading accordingly. Moreover, it was more interesting to use a complete dataset, like ReCAN, and check the validity on different types of vehicles, like an heavy truck.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9sXSc6lBAGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b720d955-b86a-42b8-bf60-757ef225c0ce"
      },
      "source": [
        "!pip install python-can"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-can\n",
            "  Downloading python-can-3.3.4.tar.gz (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.10 in /usr/local/lib/python3.7/dist-packages (from python-can) (1.12.1)\n",
            "Collecting aenum\n",
            "  Downloading aenum-3.1.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 62.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: python-can\n",
            "  Building wheel for python-can (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-can: filename=python_can-3.3.4-py2.py3-none-any.whl size=154207 sha256=f7bbf9c90ac10b68094ce5f5caa1990c40aa8fd27808792f1934ade7c257e650\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/22/aa/ab09f2d1a99925c9eb5c38e0afbb717c48fe59b74c4480d4ce\n",
            "Successfully built python-can\n",
            "Installing collected packages: aenum, python-can\n",
            "Successfully installed aenum-3.1.0 python-can-3.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUgQ7NaYAhWw"
      },
      "source": [
        "import threading\n",
        "import time\n",
        "import can\n",
        "import logging\n",
        "from base64 import b64encode, b64decode\n",
        "import datetime\n",
        "import sys\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTj2z3P5w6aF"
      },
      "source": [
        "## Logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW1qMjygxEYi"
      },
      "source": [
        "# Reference: https://www.bogotobogo.com/python/Multithread/python_multithreading_Synchronization_Producer_Consumer_using_Queue.php\n",
        "logging.basicConfig(level=logging.INFO, format='(%(threadName)-9s) %(message)s',)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3xR5v0GUazK"
      },
      "source": [
        "## Data\n",
        "\n",
        "Data was chosen from two main sources: the first one is a university and european project, that the university of Turku collaborated with, on the security of heavy trucks. The origin of the data are CAN bus logs of these trucks in normal driving conditions, without any previous attack injected.\n",
        "\n",
        "The second source came from a public research, ReCAN dataset, which is a complete resource with raw and unified data, taken from different car models on different conditions.\n",
        "\n",
        "The first step was data normalization: modify the structure of the datasets while preserving the content in order to be ingeted to our algorithm. The expected result is a series of CSV files with the following structure:\n",
        "\n",
        "| timestamp | arbitration_id | extended | remote | error | dlc | data | data | data | data | data | data | data | data |\n",
        "|:---------:|----------------|----------|--------|-------|-----|------|------|------|------|------|------|------|------|\n",
        "\n",
        "It was based on the structure of the heavy truck's dataset and the others were modified accordingly.\n",
        "- `timestamp`: the timestamp of the frame\n",
        "- `arbitration_id`: the ID of the frame\n",
        "- `extended`: it indicated if the ID is extended\n",
        "- `remote`: it indicates if the frame is a remote frame or not\n",
        "- `error`: it indicates if the frame is an errror frame or not\n",
        "- `dlc`: data length code, the length of the data\n",
        "- `data`: eight decimal values indicating the data of the frame. This is usually different between datasets: it can be expressed in hexidecimal or binary values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVmCnnUAUdYa"
      },
      "source": [
        "attackfree_datasets = [\n",
        "             '/content/2020_12_04_15_49_09_806427_vehicle.csv',\n",
        "             '/content/2020_12_07_07_54_05_363774_vehicle.csv',\n",
        "             '/content/raw11.csv',\n",
        "             '/content/raw22.csv',\n",
        "             '/content/raw33.csv',\n",
        "             '/content/test.csv'\n",
        "             ]\n",
        "\n",
        "training_fn = [\n",
        "    '/content/2021_06_22_13_10_04_728057_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_11_03_600554_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_12_02_778615_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_13_01_995553_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_14_01_213477_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_15_00_431179_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_15_59_634608_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_16_58_828128_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_17_58_001905_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_18_57_198424_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_19_56_400136_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_20_55_602416_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_21_54_811286_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_22_53_887541_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_23_53_085124_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_24_52_442638_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_25_51_772838_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_26_51_068837_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_27_50_340133_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_28_49_583673_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_29_48_854743_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_30_48_122172_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_31_47_396052_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_32_46_668090_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_33_45_860518_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_34_45_136631_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_35_44_916969_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_36_44_743770_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_37_44_122987_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_38_43_301819_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_39_42_558894_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_40_41_813371_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_41_41_075228_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_42_40_314591_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_43_39_531373_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_44_38_749345_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_45_37_974657_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_46_37_181616_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_47_36_409704_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_48_35_630889_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_49_34_833695_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_50_33_964979_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_51_32_864148_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_52_32_392879_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_53_31_499819_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_54_30_643057_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_55_29_829240_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_56_29_051575_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_57_28_450536_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_58_28_044336_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_13_59_27_574745_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_00_27_012099_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_01_26_539580_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_02_26_180494_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_03_25_575464_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_04_25_057171_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_05_24_619667_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_06_23_979033_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_07_23_539428_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_08_23_007943_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_09_22_554866_vehicle_normalized.csv',\n",
        "    '/content/2021_06_22_14_10_22_089648_vehicle_normalized.csv'\n",
        "]\n",
        "\n",
        "detection_fn = [\n",
        "                '/content/2021_06_22_14_11_21_675720_vehicle_dos.csv'            \n",
        "                \n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPAdHtxPCVxH"
      },
      "source": [
        "## Importing data\n",
        "\n",
        "The method used to import the data was modified from the original CSVReader of the `python-can` module. It gets a CSV file and returns a list of CANMessages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtA3ui3YG-jH"
      },
      "source": [
        "# Credits to: https://python-can.readthedocs.io/en/master/_modules/can/io/csv.html#CSVReader\n",
        "class CSVReader(can.io.generic.BaseIOHandler):\n",
        "    \"\"\"Iterator over CAN messages from a .csv file that was\n",
        "    generated by :class:`~can.CSVWriter` or that uses the same\n",
        "    format as described there. Assumes that there is a header\n",
        "    and thus skips the first line.\n",
        "\n",
        "    Any line separator is accepted.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file):\n",
        "        \"\"\"\n",
        "        :param file: a path-like object or as file-like object to read from\n",
        "                     If this is a file-like object, is has to opened in text\n",
        "                     read mode, not binary read mode.\n",
        "        \"\"\"\n",
        "        super(CSVReader, self).__init__(file, mode='r')\n",
        "\n",
        "    def __iter__(self):\n",
        "        # skip the header line\n",
        "        try:\n",
        "            next(self.file)\n",
        "        except StopIteration:\n",
        "            # don't crash on a file with only a header\n",
        "            return\n",
        "\n",
        "        for row,line in enumerate(self.file):\n",
        "\n",
        "            # Line reading was modified for our format\n",
        "            timestamp, arbitration_id, extended, remote, error, dlc, data0, data1, data2, data3, data4, data5, data6, data7 = line.split(',')\n",
        "\n",
        "            date, time = timestamp.split(' ')\n",
        "            year, month, day = date.split('-')\n",
        "            hour, minute, seconds = time.split(':')\n",
        "            seconds = seconds.split('.')\n",
        "\n",
        "            if len(seconds) == 1:\n",
        "                seconds.append('000000')\n",
        "\n",
        "            dt = datetime.datetime(int(year), int(month), int(day), int(hour), int(minute), int(seconds[0]), int(seconds[1]))\n",
        "            data_temp = [data0 , data1, data2, data3, data4, data5, data6, data7.rstrip('\\n')]\n",
        "\n",
        "            data = []\n",
        "            for i in range(len(data_temp)):\n",
        "                if data_temp[i] != '':\n",
        "                    data.append(int(data_temp[i]))\n",
        "            yield can.Message(\n",
        "                timestamp=dt.timestamp(),\n",
        "                is_remote_frame=(True if dlc=='0' else False),\n",
        "                is_extended_id=(True),\n",
        "                is_error_frame=(False),\n",
        "                arbitration_id=int(arbitration_id, base=16),\n",
        "                dlc=int(dlc),\n",
        "                data=(data if dlc!='0' else None),\n",
        "                check=True\n",
        "            )\n",
        "\n",
        "        self.stop()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPCiNpOEJ07W"
      },
      "source": [
        "## Choice of IDS\n",
        "\n",
        "Choosing the proper IDS from literature was a interesting but at the same time challenging task. The IDS were split into different group according to their detection method. ... (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBiVxJ0eL5-6"
      },
      "source": [
        "## 1. IDS based on frequency of each message frame\n",
        "\n",
        "The first IDS implemented was the one proposed by Gmiden et al. [fonte]. The main idea is checking each message time frame from each other (for example, when the IDS receives a message of if `0xA1B` check the timestamp of the last message with the same id). The IDS calculates the difference between the current timeframe and check if it is less than half of the shortest timeframe calculated so far. In this case an alarm is raised, otherwise if the timeframe is just shorter, the new timeframe is saved. The IDS ignores the remote frames and the answer of those (because we suppose that are \"out of regular frequency\"). The detection based on the frequency starts from the assumption that CAN messages are sent periodically through the CAN bus, so we can assume that a message with id know is sent out of the normal period, an attack is possibly in act. On the other hand, if an ECU is compromised and can send messages with its original frequency, the attack is not detected. Another disadvantage is the status of the car when the IDS is working: in fact, a vehicle sends some message with different frequency when it is running or when it is parked. This factor should be considered if OEM wants to implement this IDS. The solution can be a frequency-based IDS installed on the car that change its mode according to the state of the vehicle, and saves the timeframes in different datasets to avoid unwanted collisions or false positives. In this study, a single state of the vehicle is considered because the IDS is not connected physically to a CAN bus, but the messages are read from a log file, and there is no way to detect the different states. The IDS does not have any validation phase and can be run in real time. When an anomaly is detected the alarm is immediately raised."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_5rLqg5wmxx"
      },
      "source": [
        "class IDS_timeframe:\n",
        "    def __init__(self, filename=None, name=None, args=(), kwargs=None, verbose=None):\n",
        "        self.name = name\n",
        "        self.filename = filename\n",
        "        return\n",
        "\n",
        "    def run(self):\n",
        "        min_tolerance = {}\n",
        "        last_timestamp = {}\n",
        "        ignore_next_msg = {}\n",
        "        logging.debug(self.name + \" fired up\")\n",
        "        i = 0\n",
        "\n",
        "        for msg in CSVReader(self.filename):\n",
        "            if msg is None:\n",
        "                logging.info('No message has been received')\n",
        "                sys.exit()\n",
        "            else:\n",
        "                if msg.dlc != 0 and (msg.arbitration_id not in ignore_next_msg):\n",
        "                    if msg.arbitration_id in last_timestamp:\n",
        "                        time_frame = msg.timestamp - last_timestamp[msg.arbitration_id]\n",
        "                        if msg.arbitration_id not in min_tolerance:\n",
        "                            min_tolerance[msg.arbitration_id] = time_frame\n",
        "                        else:\n",
        "                            if time_frame < (min_tolerance[msg.arbitration_id]/2):\n",
        "                                logging.error(\"ATTACK detected: i=\" + str(i) + \" \" + str(msg) + \" \" + str(time_frame) + \" \" + str(min_tolerance[msg.arbitration_id]/2))\n",
        "                                min_tolerance[msg.arbitration_id] = time_frame\n",
        "                            elif time_frame < min_tolerance[msg.arbitration_id]:\n",
        "                                min_tolerance[msg.arbitration_id] = time_frame\n",
        "\n",
        "                    last_timestamp[msg.arbitration_id] = msg.timestamp\n",
        "                # ignore the response of the remote frame, time frequency analysis would detect attack here\n",
        "                elif msg.dlc != 0 and (msg.arbitration_id in ignore_next_msg):\n",
        "                    del ignore_next_msg[msg.arbitration_id]\n",
        "                # ignore the remote frame\n",
        "                else:\n",
        "                    ignore_next_msg[msg.arbitration_id] = True\n",
        "            i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki2nIXH725VN"
      },
      "source": [
        "### Execution\n",
        "This is the execution of of the first IDS without any attack to check its functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OQkyKO-28Ug",
        "outputId": "2285b470-3b97-4ba7-b6ed-137b64daf48b"
      },
      "source": [
        "ids_timeframe = IDS_timeframe(\n",
        "        name='ids_timeframe',\n",
        "        filename=attackfree_datasets[0])\n",
        "\n",
        "ids_timeframe.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(MainThread) ATTACK detected: i=7990 Timestamp: 1607326820.338610    ID: 18fe40f6    X                DLC:  8    0c 00 ff ff cc ff ff ff 0.017151832580566406 0.04993748664855957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjrLx4PXCJSj"
      },
      "source": [
        "## 2. IDS based on matrix of message id transitions\n",
        "\n",
        "The second IDS analysed is developed by Marchetti and Stabili [fonte] and its main assumption is that the messages flows through the CAN bus following a consistent pattern, meaning that it is possible to find sequences of message ids that repeats over time. In particular, during similar driving condition, a transition between `id_1` and `id_2` (first the ids receives `id_1` and then the following message has `id_2`) it is a consistent pattern. If the transition is new (at least one of the id was never seen before or the pattern `id_1`->`id_2` is not in the database) it is very probable that an attack is happening. This IDS needs a training phase to build up a transition matrix with in each row the origin id and in each column the destination id, and a validation phase to verify that the matrix is complete and, if not, add more transition. After that, the IDS is ready to detect in real time if there are unknown transitions and/or unknknown ids and raise alarms. One of the main strength of this IDS is the ability to detect message with unknown id, but at the same time it can be a weakness, if the id was never seen during the training phase, but the message is genuine. In order to have a complete matrix, the training phase should accept a great amount of messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep28MVYJnWh4"
      },
      "source": [
        "class IDS_transitions:\n",
        "    def __init__(self, tranining_filename=None, detection_filename=None, name=None, args=(), kwargs=None, verbose=None):\n",
        "        self.name = name\n",
        "        self.training_filename = tranining_filename\n",
        "        self.detection_filename = detection_filename\n",
        "        self.MAX_SIZE = 150\n",
        "        return\n",
        "\n",
        "    def run(self):\n",
        "        i = 0\n",
        "        last_id = 0\n",
        "        anomaly_counter = 0\n",
        "        unique_id = {}\n",
        "        matrix_index = 0\n",
        "\n",
        "        matrix = np.zeros((self.MAX_SIZE, self.MAX_SIZE))\n",
        "        logging.debug(\"starting IDS\")\n",
        "        for msg in CSVReader(self.training_filename):\n",
        "\n",
        "            if i != 0:\n",
        "                if last_id not in unique_id:\n",
        "                    unique_id[last_id] = matrix_index\n",
        "                    matrix_index+=1\n",
        "                if msg.arbitration_id not in unique_id:\n",
        "                    unique_id[msg.arbitration_id] = matrix_index\n",
        "                    matrix_index+=1\n",
        "                \n",
        "                matrix[unique_id[last_id]][unique_id[msg.arbitration_id]] = 1\n",
        "\n",
        "            last_id = msg.arbitration_id\n",
        "            i+=1\n",
        "\n",
        "        print(matrix)\n",
        "        i = 0\n",
        "        anomaly_counter = 0\n",
        "\n",
        "        unknown_ids = {}\n",
        "        for msg in CSVReader(self.detection_filename):\n",
        "            \n",
        "            if i != 0:\n",
        "                if last_id not in unique_id:\n",
        "                    # logging.info(\"ANOMALY detected in transition: \" + str(last_id) + \" -> \" + str(msg.arbitration_id))\n",
        "                    anomaly_counter += 1\n",
        "                    continue\n",
        "                elif msg.arbitration_id not in unique_id:\n",
        "                    anomaly_counter +=1\n",
        "                    if msg.arbitration_id not in unknown_ids:\n",
        "                        unknown_ids[msg.arbitration_id] = 1\n",
        "                    else:\n",
        "                        unknown_ids[msg.arbitration_id] += 1\n",
        "                    continue\n",
        "                else:\n",
        "                    if not matrix[unique_id[last_id]][unique_id[msg.arbitration_id]]:\n",
        "                        # logging.info(\"ANOMALY detected in transition: \" + str(last_id) + \" -> \" + str(msg.arbitration_id))\n",
        "                        anomaly_counter += 1\n",
        "            \n",
        "            i+=1\n",
        "            last_id = msg.arbitration_id\n",
        "        logging.info(\"number of anomalies detected: \" + str(anomaly_counter))\n",
        "        logging.info(\"unknown id: \" + str(unknown_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR2II4RApGFC"
      },
      "source": [
        "### Execution\n",
        "\n",
        "This is the execution of the second IDS with attack free dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQPewTz8pQAV",
        "outputId": "9d4ffadb-e3a0-44b4-f799-a167cb8b7621"
      },
      "source": [
        "ids_transitions = IDS_transitions(\n",
        "        name='ids_transitions', \n",
        "        tranining_filename=attackfree_datasets[2], \n",
        "        detection_filename=attackfree_datasets[3])\n",
        "  \n",
        "ids_transitions.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [1. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(MainThread) number of anomalies detected: 1691\n",
            "(MainThread) unknown id: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yDhqXklPOwh"
      },
      "source": [
        "## 3. IDS based on the hamming distance of frames with the same id\n",
        "\n",
        "The following IDS follows the idea of Stabili et al. in [fonte]. Its functioning is based on the assumption that the Hamming distance of consequent messages (with the same id) will always be inside a certain range. This range is calculate during the training and validation phase. During the live detection phase, if a message has an Hamming distance smaller or larger than this range, an alarm is raised because it is very likely that an attack is happening. Based on its definition, this IDS seems very good in detecting replay attacks and fuzzing attack with malicious messages with id already seen. On the other hand, a message with unknown id is ignored, so attacks like DoS with high priority message can be ignored during the execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjNiK66gTTul"
      },
      "source": [
        "class IDS_hamming:\n",
        "    def __init__(self, tranining_filenames=None, detection_filenames=None, name=None, args=(), kwargs=None, verbose=None):\n",
        "        self.name = name\n",
        "        self.training_filenames = tranining_filenames\n",
        "        self.detection_filenames = detection_filenames\n",
        "        return\n",
        "\n",
        "    def hamming(self, data1, data2):\n",
        "        if len(data1) != len(data2):\n",
        "            logging.error(\"messages with different length!\")\n",
        "            return 0\n",
        "        else:\n",
        "            length = len(data1)\n",
        "            hamming_distance = 0\n",
        "            for i in range(length):\n",
        "                 byte_distance = bin(data1[i] ^ data2[i]).count('1')\n",
        "                 hamming_distance += byte_distance\n",
        "            \n",
        "            return hamming_distance\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.min_hamming = {}\n",
        "        self.max_hamming = {}\n",
        "\n",
        "        for filename in self.training_filenames:\n",
        "            last_msg = {}\n",
        "\n",
        "            for msg in CSVReader(filename):\n",
        "\n",
        "                if msg.arbitration_id in last_msg:\n",
        "\n",
        "                    current_hamming = self.hamming(msg.data,last_msg[msg.arbitration_id].data)\n",
        "\n",
        "                    if msg.arbitration_id not in self.min_hamming:\n",
        "                        self.min_hamming[msg.arbitration_id] = current_hamming\n",
        "                        self.max_hamming[msg.arbitration_id] = current_hamming\n",
        "                    else:\n",
        "                        if current_hamming > self.max_hamming[msg.arbitration_id]:\n",
        "                            self.max_hamming[msg.arbitration_id] = current_hamming\n",
        "                        elif current_hamming < self.min_hamming[msg.arbitration_id]:\n",
        "                            self.min_hamming[msg.arbitration_id] = current_hamming\n",
        "\n",
        "                last_msg[msg.arbitration_id] = msg\n",
        "\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "\n",
        "        for filename in self.detection_filenames:\n",
        "\n",
        "            last_msg = {}\n",
        "            anomaly_counter = 0\n",
        "\n",
        "            for msg in CSVReader(filename):\n",
        "\n",
        "                if msg.arbitration_id in last_msg:\n",
        "\n",
        "                    current_hamming = self.hamming(msg.data,last_msg[msg.arbitration_id].data)\n",
        "\n",
        "                    if msg.arbitration_id not in self.min_hamming:\n",
        "                        logging.info(\"new ID detected: \" + str(msg.arbitration_id))\n",
        "                    else:\n",
        "                        if current_hamming > self.max_hamming[msg.arbitration_id] or current_hamming < self.min_hamming[msg.arbitration_id]:\n",
        "                            anomaly_counter +=1\n",
        "\n",
        "                last_msg[msg.arbitration_id] = msg\n",
        "\n",
        "            logging.info(\"anomalies encountered: \" + str(anomaly_counter))\n",
        "        \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsQoGJcdYHgq"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLKDOkGsYKNE"
      },
      "source": [
        "ids_hamming = IDS_hamming(\n",
        "    training_fn,\n",
        "    detection_fn,\n",
        "    'ids_hamming')\n",
        "ids_hamming.train()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llCdsTIRUU7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a10909-0f78-497c-9300-9b2c953105e8"
      },
      "source": [
        "ids_hamming.detection_filenames = ['/content/2021_06_22_14_11_21_675720_vehicle_dos_1rand.csv']\n",
        "ids_hamming.run()\n",
        "print(ids_hamming.max_hamming)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 419412607\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 418185087\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 201385599\n",
            "(MainThread) new ID detected: 418119551\n",
            "(MainThread) new ID detected: 285179775\n",
            "(MainThread) new ID detected: 418185087\n",
            "(MainThread) new ID detected: 285179775\n",
            "(MainThread) new ID detected: 285179775\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 419412607\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 419412607\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 418185087\n",
            "(MainThread) new ID detected: 201385599\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 419412607\n",
            "(MainThread) new ID detected: 418185087\n",
            "(MainThread) new ID detected: 418119551\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 418119551\n",
            "(MainThread) new ID detected: 418119551\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 419412607\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 285179775\n",
            "(MainThread) new ID detected: 201385599\n",
            "(MainThread) new ID detected: 418119551\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 285179775\n",
            "(MainThread) new ID detected: 285183871\n",
            "(MainThread) new ID detected: 419319782\n",
            "(MainThread) new ID detected: 419406207\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 285179775\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) new ID detected: 419408614\n",
            "(MainThread) anomalies encountered: 1009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{285180134: 10, 418384358: 29, 217055974: 20, 217056486: 26, 150892262: 43, 218000614: 18, 369055206: 5, 217056230: 12, 369055974: 8, 285110248: 15, 284166120: 1, 419322856: 3, 417726408: 0, 417726400: 0, 417726392: 0, 417726384: 0, 417726376: 0, 369056230: 0, 419284198: 1, 486510675: 2, 419349704: 0, 419373030: 15, 217996006: 0, 419349696: 0, 418383334: 16, 419349688: 0, 419322342: 17, 419349680: 0, 369056998: 4, 419349672: 8, 419315958: 3, 419323080: 0, 419361254: 15, 419323072: 0, 419361510: 10, 419239398: 1, 419323064: 0, 419323056: 0, 418382310: 7, 419323048: 0, 419370470: 0, 416350182: 0, 418119654: 43, 486506726: 0, 419396326: 7, 419360742: 7, 419358438: 11, 418185190: 5, 417398758: 1, 418383590: 0, 419364070: 5, 419360486: 10, 486458342: 0, 419389414: 21, 419363046: 9, 419362278: 9, 419321574: 2, 419405798: 20, 419402982: 18, 419403238: 11, 419344102: 10, 419265766: 0, 419236326: 13, 419348966: 26, 419422182: 0, 419358182: 5, 486535398: 0, 486535654: 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6iawT0i7vcv"
      },
      "source": [
        "## IDS based on the entropy of ID CAN message bits\n",
        "\n",
        "The next IDS analysed is developed by Wang and colleagues [fonte], and its detection technique is based on the entropy of each bit of a regular or extended message arbitration ID. Since the data considered in this study uses extended ID, this will be the type of IDs analysed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DOoPn8D8oiY"
      },
      "source": [
        "class IDS_Id_Entropy:\n",
        "    def __init__(self, tranining_filenames=None, detection_filenames=None, name=None, args=(), kwargs=None, verbose=None):\n",
        "        self.name = name\n",
        "        self.training_filenames = tranining_filenames\n",
        "        self.detection_filenames = detection_filenames\n",
        "        return\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        entropy_vectors = np.zeros((len(self.training_filenames), 29))\n",
        "\n",
        "        K = 5\n",
        "\n",
        "        for filename_index, filename in enumerate(self.training_filenames):\n",
        "            probability_vector = np.zeros(29)\n",
        "\n",
        "            messages = CSVReader(filename)\n",
        "\n",
        "            num_of_messages = 0\n",
        "\n",
        "            for msg in messages:\n",
        "                \n",
        "                b_arbitration_id = format(msg.arbitration_id, \"029b\")\n",
        "\n",
        "                for i in range(len(b_arbitration_id)):\n",
        "                    if b_arbitration_id[i] == '1':\n",
        "                        probability_vector[i] += 1\n",
        "                \n",
        "                num_of_messages += 1\n",
        "            \n",
        "            probability_vector = np.divide(probability_vector, float(num_of_messages))\n",
        "\n",
        "\n",
        "            for i in range(len(probability_vector)):\n",
        "\n",
        "                if probability_vector[i] == 1.0 or probability_vector[i] == 0.0:\n",
        "                     entropy_vectors[filename_index][i] = 0.0\n",
        "                elif probability_vector[i] > 0.0:\n",
        "                    # H(X) = H_b(p) = -p * log_2(p)-(1-p)log_2(1-p) \n",
        "                    entropy_vectors[filename_index][i] = -(probability_vector[i]) * math.log2(probability_vector[i]) - (1.0 - probability_vector[i]) * math.log2(1.0 - probability_vector[i])\n",
        "            \n",
        "\n",
        "\n",
        "        max_entropy = np.amax(entropy_vectors, axis=0)\n",
        "        min_entropy = np.amin(entropy_vectors, axis=0)\n",
        "\n",
        "\n",
        "        entropy_range = max_entropy - min_entropy\n",
        "\n",
        "        self.threshold = np.multiply(entropy_range, K)\n",
        "\n",
        "\n",
        "        print(self.threshold)\n",
        "\n",
        "        self.entropy_template = np.mean(entropy_vectors, axis=0)\n",
        "\n",
        "        print(self.entropy_template)\n",
        "\n",
        "    def run(self):\n",
        "        \n",
        "        for filename_index, filename in enumerate(self.detection_filenames):\n",
        "\n",
        "            messages = CSVReader(filename)\n",
        "\n",
        "            num_of_messages = 0\n",
        "\n",
        "            probability_vector = np.zeros(29)\n",
        "\n",
        "            entropy_vector_to_check = np.zeros(29)\n",
        "            for msg in messages:\n",
        "                \n",
        "                b_arbitration_id = format(msg.arbitration_id, \"029b\")\n",
        "\n",
        "                for i in range(len(b_arbitration_id)):\n",
        "                    if b_arbitration_id[i] == '1':\n",
        "                        probability_vector[i] += 1\n",
        "                \n",
        "                num_of_messages += 1\n",
        "            \n",
        "            probability_vector = np.divide(probability_vector, float(num_of_messages))\n",
        "\n",
        "\n",
        "            for i in range(len(probability_vector)):\n",
        "\n",
        "                if probability_vector[i] == 1.0 or probability_vector[i] == 0.0:\n",
        "                     entropy_vector_to_check[i] = 0.0\n",
        "                elif probability_vector[i] > 0.0:\n",
        "                    # H(X) = H_b(p) = -p * log_2(p)-(1-p)log_2(1-p) \n",
        "                    entropy_vector_to_check[i] = -(probability_vector[i]) * math.log2(probability_vector[i]) - (1.0 - probability_vector[i]) * math.log2(1.0 - probability_vector[i])\n",
        "\n",
        "\n",
        "            for i in range(len(entropy_vector_to_check)):\n",
        "\n",
        "                if entropy_vector_to_check[i] > (self.entropy_template[i] + self.threshold[i]):\n",
        "\n",
        "                    logging.info(\"attack detected on bit \" + str(i))\n",
        "                \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNvHF0rVFXn_"
      },
      "source": [
        "### Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbmTlk1XFZ7x",
        "outputId": "230ceaa8-04d0-4940-b120-686ec68b4e8c"
      },
      "source": [
        "entropy_ids = IDS_Id_Entropy(training_fn, detection_fn, 'entropy_ids')\n",
        "\n",
        "entropy_ids.train()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.02874571 0.05321616 0.02636567 0.         0.02037845 0.\n",
            " 0.         0.00369453 0.02045797 0.0047829  0.00624241 0.00349854\n",
            " 0.02591707 0.02651045 0.00410948 0.01414741 0.00675294 0.00336313\n",
            " 0.0019587  0.03077084 0.02609876 0.006378   0.02512278 0.0225136\n",
            " 0.0597328  0.14488687 0.08810933 0.09494428 0.006378  ]\n",
            "[0.87701268 0.74848331 0.91271323 0.         0.37026783 0.\n",
            " 0.         0.05240467 0.36762981 0.9835928  0.95287278 0.99370345\n",
            " 0.91731525 0.91049468 0.99618123 0.74180377 0.91268995 0.9951982\n",
            " 0.99834676 0.94818328 0.96145509 0.09290482 0.49004006 0.4127726\n",
            " 0.45344408 0.59103395 0.7703397  0.74864727 0.09290482]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeNK84LWbFGu",
        "outputId": "592d6da6-8083-4697-94f4-f565ae0ca164"
      },
      "source": [
        "entropy_ids.detection_filenames = ['/content/2021_06_22_14_11_21_675720_vehicle_dos_1rand.csv']\n",
        "entropy_ids.run()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "(MainThread) attack detected on bit 5\n",
            "(MainThread) attack detected on bit 6\n"
          ]
        }
      ]
    }
  ]
}